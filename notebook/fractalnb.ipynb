{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2542163c-c6b8-42a4-8db9-b204c8e8483b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dependencies and Spark context setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ed4e89-45bb-4210-8f98-a69512f9b66a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$cp.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-core:3.5.0`\n",
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import $ivy.`com.koloboke:koloboke-impl-jdk8:1.0.0`\n",
    "import $ivy.`com.typesafe.akka:akka-remote_2.13:2.5.23`\n",
    "import $cp.`/app/fractal-core-SPARK-3.5.0.jar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3558d5ae-8508-4b75-85fe-7418df071b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Getting spark JARs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Creating SparkSession\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://2da17bd0067a:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.NotebookSparkSession\u001b[39m\n",
       "\u001b[36msc\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mSparkContext\u001b[39m = org.apache.spark.SparkContext@3bedbab"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.NotebookSparkSession\n",
    "val sc = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.jars.packages\", \"com.koloboke:koloboke-impl-jdk8:1.0.0,com.typesafe.akka:akka-remote_2.13:2.5.23\")\n",
    "    .getOrCreate()\n",
    "    .sparkContext\n",
    "}\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2834b99-690e-46e8-bec1-e5b8d2d6b57e",
   "metadata": {},
   "source": [
    "## Motif listing\n",
    "1. Create FractalContext from SparkContext\n",
    "2. Create FractalGraph: unlabeled and based on the built-in adjacency lists format\n",
    "3. Create a vertex fractoid, apply 4 extension operations yielding induced subgraphs with 4 vertices\n",
    "4. Aggregate subgraphs by mapping each to its non-canonical pattern (quick) and the number 1\n",
    "5. Internally aggregationCanonicalPatternLong counts how many subgraphs of each canonical pattern exists in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d088d4-d77a-4a78-8e67-e9a4c081e3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mbr.ufmg.cs.systems.fractal.{FractalContext, FractalGraph}\u001b[39m\n",
       "\u001b[36mfc\u001b[39m: \u001b[32mFractalContext\u001b[39m = br.ufmg.cs.systems.fractal.FractalContext@2ffe2b81\n",
       "\u001b[36mfg\u001b[39m: \u001b[32mFractalGraph\u001b[39m = \u001b[33mFractalGraph\u001b[39m(\n",
       "  path = \u001b[32m\"/app/data/citeseer\"\u001b[39m,\n",
       "  graphClass = \u001b[32m\"br.ufmg.cs.systems.fractal.graph.UnlabeledMainGraph\"\u001b[39m,\n",
       "  fc = br.ufmg.cs.systems.fractal.FractalContext@2ffe2b81,\n",
       "  confs = \u001b[33mMap\u001b[39m(),\n",
       "  logLevel = \u001b[32m\"warn\"\u001b[39m,\n",
       "  edgePredicate = \u001b[32mnull\u001b[39m,\n",
       "  vertexPredicate = \u001b[32mnull\u001b[39m\n",
       ")\n",
       "\u001b[36mpatternCountRDD\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[(\u001b[32mbr\u001b[39m.\u001b[32mufmg\u001b[39m.\u001b[32mcs\u001b[39m.\u001b[32msystems\u001b[39m.\u001b[32mfractal\u001b[39m.\u001b[32mpattern\u001b[39m.\u001b[32mPattern\u001b[39m, \u001b[32mLong\u001b[39m)] = ShuffledRDD[23] at foldByKey at Fractoid.scala:401\n",
       "\u001b[36mres10_4\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mbr\u001b[39m.\u001b[32mufmg\u001b[39m.\u001b[32mcs\u001b[39m.\u001b[32msystems\u001b[39m.\u001b[32mfractal\u001b[39m.\u001b[32mpattern\u001b[39m.\u001b[32mPattern\u001b[39m, \u001b[32mLong\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\n",
       "    bliss{edges=[(0,1),(1,2),(0,2),(2,3),(1,3),(0,3)],vlabels=[1,1,1,1],elabels=[0,0,0,0,0,0]},\n",
       "    \u001b[32m255L\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    bliss{edges=[(1,2),(2,3),(1,3),(0,3)],vlabels=[1,1,1,1],elabels=[0,0,0,0]},\n",
       "    \u001b[32m22900L\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    bliss{edges=[(0,1),(0,2),(2,3),(1,3)],vlabels=[1,1,1,1],elabels=[0,0,0,0]},\n",
       "    \u001b[32m3094L\u001b[39m\n",
       "  ),\n",
       "  (\n",
       "    bliss{edges=[(1,2),(0,2),(2,3),(1,3),(0,3)],vlabels=[1,1,1,1],elabels=[0,0,0,0,0]},\n",
       "    \u001b[32m2200L\u001b[39m\n",
       "  ),\n",
       "  (bliss{edges=[(2,3),(1,3),(0,3)],vlabels=[1,1,1,1],elabels=[0,0,0]}, \u001b[32m222630L\u001b[39m),\n",
       "  (bliss{edges=[(0,2),(2,3),(1,3)],vlabels=[1,1,1,1],elabels=[0,0,0]}, \u001b[32m111153L\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import br.ufmg.cs.systems.fractal.{FractalContext, FractalGraph}\n",
    "val fc = new FractalContext(sc)\n",
    "val fg = fc.unlabeledGraphFromAdjLists(\"/app/data/citeseer\")\n",
    "val patternCountRDD = fg \n",
    "    .vfractoid // induced subgraphs\n",
    "    .extend(4) // four extension operations: induced subgraphs with 4 vertices\n",
    "    .aggregationCanonicalPatternLong(s => s.quickPattern(), 0L, s => 1L, _ + _) // count by canonical pattern\n",
    "patternCountRDD.collect() // collect result from resulting Spark RDD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
